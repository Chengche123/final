1 缓存十九式:
    一: 
        缓存是分级的: 目前主流cache分三级, 有少量商用cpu的cache分成四级
        核心访问某个地址时如果不命中(Cache miss)L1缓存的话，L1缓存控制器会从后续层级的缓存中将该地址对应的数据读入到L1缓存中。
    二: 
        **缓存是透明的**: 程序员不能细粒度的控制缓存,但可以粗粒度的操纵缓存
        如: intel CPU的
            CLFLUSH(cache line flush)指令: 将缓存中的某项数据写回到内存(如果已修改), **并删除对应的缓存行**
            CLWB(cache line write back)指令: 将缓存中的某项数据写回到内存(如果已修改), **但不删除对应的缓存行**
    三:
        缓存的容量,频率和延迟
    四:
        私有缓存和共享缓存
    五:
        Inclusive模式和Exclusive模式
    六:
        **Dirty标记和Invalid标记**
        cache行更新过会将Dirty位置1, 没更新过保持0. **在腾出cache行时如果Dirty位为1要写回, 否则直接覆盖就行**
        cache行的Invalid位用来应对多个核心同时访问某个地址数据的场景, 为1时表示可以**不写回直接覆盖**, 为0则不可以被覆盖
    七:
        缓存行
        利用空间局部性, 目前**主流CPU的缓存行大小都采用64字节**, 其主要原因是主流的DDR SDRAM一次连续数据传输通常最大只能到64字节
    八:
        全关联/直接关联/组关联
    九:
        用虚拟地址查缓存
        CPU核心取指单元发出的都是虚拟地址, CPU内部的MMU会负责将虚拟地址转换为物理地址, 而缓存中的Tag则是物理地址
        因为虚拟地址和其对应的物理地址的低(log2页面容量)位是相同的, **如果设计得当, 可以直接用虚拟地址来做第一次匹配**
    十:
        缓存的同名问题
        总结起来就是, 现代CPU**不完全使用虚拟地址来找cache行**, 而是**和MMU转换后得到的物理地址结合起来找**
    十一:
        缓存的别名问题
        同一个物理地址可能会被映射到不同的虚拟地址, 这对cache没有任何问题, 不管有多少个虚拟地址指向该物理地址, 其内容总会被定位到单个固定位置, 也不会被误判
    十二:
        页面着色
    十三:
        小结及商用CPU的缓存模式
    十四:
        **缓存对写入操作的处理**
        在向缓存行中写入数据之前，需要先将其内容填充好，这个过程叫作**写分配(write allocate)**，或者**行填充(Line fill)**。如果某个行已经被填充上来了，向其中写入一个或者多个字节时就会写命中。如果对应行的内容尚未被填充，向其中写入字节会发生写不命中，此时，就要先进行写分配再将这行的内容写进去。
    十五:
        Load/Stor Queue与Stream Buffer
    十六:
        非阻塞缓存与MSHR
    十七:
        **缓存行替换策略**
        在替换时, 如果**Dirty为1要先写回再覆盖**, 如果**Invalid为1时就不需要写回, 可以直接覆盖**; Invalid位用于解决缓存一致性问题
    十八:
        **i_Cache/d_Cache/TLB_Cache**
        TLB，这个缓存非常关键，因为在核心访问iCache/dCache之前，**必须先经过TLB查出物理地址**(对于PIPT模式的iCache/dCache而言)，TLB的命中率直接决定了整体的性能，否则后续缓存即便采用了宇宙无敌优化方法，在TLB产生瓶颈的话，犹如竹篮打水。  
        如果线程调度程序调度了另外一个进程中的线程执行，那么此时**由于虚拟地址空间被整体切换，TLB之前缓存过的内容就必须被清空**，否则会翻译出错误的物理地址，因为不同进程可能会发出相同的虚拟地址，但是它们对应的物理地址是不同的，所以必须清空TLB，然后开始预热过程(从存储在SDRAM的页表中逐渐将表项提取填充到TLB)。这个代价太大了，因为进程切换的频率非常频繁，每10ms可能就会切换一次。人们的做法是**给TLB中每个表项增加一列，记录该表项对应的进程ID**，这样就可以区分开。**切换进程之后，不必清空**，查找的时候只去尝试匹配与当前运行的进程ID匹配的那些条目即可。
    十九:
        **对齐和伪共享**
            对齐问题: 
                由于**缓存是以缓存行而不是字节为最小管理粒度的**，这在一定程度上带来了不少问题。首先就是对齐问题。假设某个程序生成了一个数组，大小为64字节，一个缓存行也为64字节，但是这个数组的起始地址并没有与缓存行对齐，跨越了两个缓存行。如果程序针对该数组内的数据开始不停地读写，那么必须从下级存储器读出被跨越的这两个缓存行，而不是仅一个(如果这64字节被放置到一行里的话)，这就产生了读惩罚。所以，**编译器在这里会起到很大的优化作用，其会尽力保证变量位于的地址与缓存行的粒度是对齐的**。对于**那些由程序动态申请的内存(堆)，程序要负责手动地将数据存储到这些内存中，此时就需要程序员来避免产生不对齐问题。**
            伪共享:
                简介:
                    如果**两个线程各自访问各自的变量，而这两个变量数据处在同一个缓存行中**。这个是高概率事件，因为OS对一个进程的内存一般是按照4KB页面为粒度来分配的，该进程内部的多个线程所操纵的数据有很高的概率落在同一个4KB之内，也有很高的概率落在同一个64字节缓存行内。但是，**这两个线程却偏偏被线程调度程序分派到了两个不同的CPU核心上运行**，而**不同的CPU核心各有各的L1/L2缓存**，所以该缓存行会被载入这两个核心的L1缓存中，此时**会频繁的同步不同核心间的缓存, 性能非常差!**
                **解决办法(编译器或者程序员自己控制**):
                    伪共享是可以解决的，比如将同一个进程的多个线程所操作的变量数据打散到多个不会引发冲突的缓存行内存放，也就是**在编译的时候主动分配到对应的地址上**，这叫作**缓存行对齐( cache line align)**，还有一种做法是进行缓存行填充，如果某个变量占不了一个缓存行，为了防止其他变量与自己共享该缓存行而导致的潜在性能问题，索性**在程序代码中主动生成一些填充数据来将缓存行剩余容量塞满，以阻止它与其他变量共享该空间**，这种方式对**内存浪费很严重**，被称为**缓存行填充**(cache line padding)。
                Go复现(伪共享): 
                    func main() {
                        s := make([]int32, 2)
                        var wg sync.WaitGroup

                        wg.Add(1)
                        go func() {
                            defer wg.Done()

                            for {
                                s[0]++

                                if s[0] == math.MaxInt32 {
                                    return
                                }

                            }

                        }()

                        wg.Add(1)
                        go func() {
                            defer wg.Done()

                            for {
                                s[1]++

                                if s[1] == math.MaxInt32 {
                                    return
                                }
                            }
                        }()

                        pre := time.Now()
                        wg.Wait()
                        now := time.Now()

                        fmt.Println(now.Sub(pre)) // 4.0176524s
                    }
                Go复现(缓存行填充): 
                    func main() {
                        s := make([]int32, 17)
                        var wg sync.WaitGroup

                        wg.Add(1)
                        go func() {
                            defer wg.Done()

                            for {
                                s[0]++

                                if s[0] == math.MaxInt32 {
                                    return
                                }

                            }

                        }()

                        wg.Add(1)
                        go func() {
                            defer wg.Done()

                            for {
                                s[16]++

                                if s[16] == math.MaxInt32 {
                                    return
                                }
                            }
                        }()

                        pre := time.Now()
                        wg.Wait()
                        now := time.Now()

                        fmt.Println(now.Sub(pre)) // 2.7994189s
                    }








            









