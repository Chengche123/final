1 goroutine和kst的区别:
    一: 内存占用: 创建一个g的栈内存消耗只有2kb,并且支持扩容,kst的栈内存为1-8MB,并且无法改变,有溢出风险
    二: 创建/销毁: 线程的创建和销毁会陷入内核,开销非常大,而g的创建和销毁在用户态,开销很小
    三: 调度切换: 除了陷入内核外,kst上下文切换时保存的的寄存器(PC,IR,PSW,堆栈指针和各种通用寄存器和特殊寄存器)较多,
        为了公平性还需要进行复杂的计算,开销比较大,而g的切换在用户态并且需要保存的上下文信息极少,开销小得多
    四: 复杂性: 不能大量创建kst,使用多路复用时存在大量callback

2 GMP概念:
    一: G 使用struct runtime.g,每次go func()都会产生一个G,包含状态 堆栈和上下文
    二: M kst也被称作machine,使用struct runtime.m管理,所以m是有线程栈的,当指定了线程栈,也就是m.stack->g.stack,
        m的pc寄存器指向g提供的函数,然后去执行
    三: P 使用struct runtime.p,将等待执行的g与m对接,当p可运行队列(runq)有g时需要新建或者唤醒一个m来执行
        p与m需要进行绑定,p决定了并行任务的数量,可以通过runtime.GOMAXPROCS来改变,默认为逻辑核数
        一个P代表执行一个Go代码片段所必需的资源（或称“上下文环境”）

3 GM调度模型的问题: 1.12前的调度器
    一: 存在单一全局互斥锁: 导致所有g的创建,结束和重新调度都要上锁
    二: goroutine传递: 刚创建的g都会放进全局队列,而不是本地m执行
    三: m.mcache: 每个m持有mcache(和g内存分配有关),只有m在执行go代码时才需要这个,执行syscall时并不需要,造成浪费
        内存亲缘性也差,g被调度到同一个m的几率不高,数据局部性不好
    四: 严重的线程阻塞和解锁: m找不到g时频繁的阻塞/唤醒来执行检查逻辑,以便及时发现新的g来运行

4 GMP调度
    一: mcache从M移到了P,而G队列也被分成两类，保留全局G队列，同时每个P中都会有一个本地的G队列;
        m会从本地p队列,全局队列或者其他p队列找g运行;因为Work-stealing,p队列可能会并发访问,所以p队列是CAS实现的LockFree队列
    二: Work-stealing
        1) 当一个p执行完本地所有g之后,会尝试从其他p中窃取一半g(CAS自旋),尝试若干次都失败后就会从全局队列捞(当前个数/GOMAXPROCS)个g
        2) runtime.schedule:
            1: 每61轮调度之后,尝试从全局队列获取g
            2: 如果没有找到,尝试从本地p队列获取g
            3: 如果没有找到,循环从其他p队列,本地p队列,全局队列,poll network获取g,直到拿到可运行的g为止(runtime.findrunnable)
    三: 全局队列: 新建g时P的runq放不下已满并达到256个的时候会放半数G到全局队列去，阻塞的系统调用返回时找不到空闲P也会放到全局队列。


.1 协程优点：// TODO 删除
    一:避免了内核态和用户态的切换导致的成本,包括内存的分配与释放，都是在用户态维护着一块大的内存池， 
       不直接调用系统的malloc函数（除非内存池需要改变）








