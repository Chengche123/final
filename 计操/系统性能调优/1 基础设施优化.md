1 CPU缓存:
    一: 
        CPU 缓存分为数据缓存与指令缓存，对于数据缓存，我们应**在循环体中尽量操作同一块内存上的数据**，由于缓存是根据CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时也有性能提升。
    二:
        对于指令缓存，有规律的条件分支能够让 CPU 的**分支预测**发挥作用，进一步提升执行效率。对于多核系统，如果进程的缓存命中率非常高，则可以考虑绑定 CPU 来提升缓存命中率。

2 在栈上分配内存
    一: 优点
        每个线程都有独立的栈，所以分配内存时不需要加锁保护，而且栈上对象的尺寸在**编译阶段**就已经写入可执行文件了，执行效率更高！
        性能至上的 Golang 语言就是按照这个逻辑设计的，即使你用new关键字分配了堆内存，但编译器如果认为在栈中分配不影响功能语义时，会自动改为在栈中分配。
    一: 缺点
        它有功能上的限制。一是， 栈内存**生命周期**有限，它会随着函数调用结束后自动释放。在堆中分配的内存，并不随着分配时所在函数调用的结束而释放，它的生命周期足够使用；二是，栈的**容量有限**，如 CentOS 7 中是 8MB 字节，如果你申请的内存超过限制会造成栈溢出错误（比如，递归函数调用很容易造成这种问题），而堆则没有容量限制。

3 索引:
    一: 两种解决哈希冲突的方法
        **链接法**，落到数组同一个位置中的多个数据，通过链表串在一起。使用哈希函数查找到这个位置后，再使用链表遍历的方式查找数据。Java 标准库中的哈希表就使用链接法解决冲突。
        **开放寻址法**，插入时若发现对应的位置已经占用，或者查询时发现该位置上的数据与查询关键字不同，开放寻址法会按既定规则变换哈希函数（例如哈希函数设为 H(key,i)，顺序地把参数 i 加 1），计算出下一个数组下标，继续在哈希表中探查正确的位置。
    二: **哈希表,红黑树,B树**
        因为哈希表本身没办法找到关键字相邻的下一个元素，所以**哈希表不支持范围查询与遍历**。如果业务**需要支持范围查询时**，我们需要**考虑红黑树、B 树等**索引，它们其实并不慢。当索引太大，必须将一部分从内存中移到硬盘时，B 树就是一个很好的选择。
    
4 零拷贝:
    一:
        **基于用户缓冲区传输文件时**，过多的**内存拷贝与上下文切换**次数会降低性能。零拷贝技术在内核中完成内存拷贝，天然降低了内存拷贝次数。它**通过一次系统调用合并了磁盘读取与网络发送两个操作**，降低了上下文切换次数。尤其是，由于拷贝在内核中完成，它**可以最大化使用 socket 缓冲区的可用空间**，从而提高了一次系统调用中处理的数据量，进一步降低了上下文切换次数。
    二:
        **零拷贝技术基于 PageCache**，而 PageCache 缓存了最近访问过的数据，提升了访问缓存数据的性能，同时，为了解决机械磁盘寻址慢的问题，它还协助 IO 调度算法实现了 IO 合并与预读（这也是顺序读比随机读性能好的原因），这进一步提升了零拷贝的性能。几乎所有操作系统都支持零拷贝，如果**应用场景就是把文件发送到网络中**，那么我们应当选择使用了零拷贝的解决方案。
    三: **缺点**
        不允许进程对文件内容作一些加工再发送，比如数据压缩后再发送。另外，当 PageCache 引发负作用时，也不能使用零拷贝，此时可以用异步 IO+直接 IO 替换。我们通常会设定一个文件大小阈值，**针对大文件使用异步 IO 和直接 IO**，而**对小文件使用零拷贝**。

5 锁:
    一: 互斥锁
        互斥锁能够满足各类功能性要求，特别是被锁住的代码执行时间不可控时，它**通过内核执行线程切换**及时释放了资源，但它的性能消耗最大。
    二: 自旋锁
        如果能够确定被锁住的代码取到锁后很快就能释放，应该使用更高效的自旋锁，它特别适合基于异步编程实现的高并发服务。
        自旋锁比互斥锁快得多，因为它**通过CPU提供的 CAS 函数**（全称 Compare And Swap），**在用户态**代码中完成加锁与解锁操作。
    三: 读写锁
        读优先锁和写优先锁:
            **读优先锁更强调效率**，它期待锁能被更多的线程持有。简单看下它的工作特点：当线程 A先持有读锁后，即使线程 B 在等待写锁，后续前来获取读锁的线程 C 仍然可以立刻加锁成功，因为这样就有 A、C 这 2 个读线程在并发持有锁，效率更高。
            **写优先的读写锁**。同样的情况下，线程 C 获取读锁会失败，它将被阻塞在获取锁的代码中，这样，只要线程 A 释放读锁后，线程 B 马上就可以获取到写锁。
            **读优先锁并发性更好**，但问题也很明显。**如果读线程源源不断地获取读锁，写线程将永远获取不到写锁**。**写优先锁可以保证写线程不会饿死**，但如果新的写线程源源不断地到来，读线程也可能被饿死。
        公平读写锁:
            **用队列把请求锁的线程排队**，按照先来后到的顺序加锁即可，当然**读线程仍然可以并发，只不过不能插队到写线程之前。**
    四: 乐观锁
            什么叫悲观锁: 先加锁再修改共享资源
                它认为同时修改资源的概率很高，很容易出现冲突，所以**访问共享资源前，先加上锁**，总体效率会更优。
                无论**互斥锁、自旋锁还是读写锁，都属于悲观锁**。
            乐观锁: 先修改共享资源再**验证**
                如果**并发产生冲突的概率很低**，就不必使用悲观锁，而是**使用乐观锁**。然而，一旦冲突概率上升，就不适合使用它，因为它解决冲突的**重试成本非常高**。
                所谓“乐观”，就是假定冲突的概率很低，所以它采用的“加锁”方式是，**先修改完共享资源，再验证这段时间内有没有发生冲突。如果没有其他线程在修改资源，那么操作完成。**














